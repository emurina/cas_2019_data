{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XvMlNQwb8PtU"
   },
   "source": [
    "## Hello World in Deep Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KZSmMIb4fRRd"
   },
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cd7dh5Cd8PtW"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tensorflow.keras.models import Sequential, Model, clone_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KMNOTvj8fRRi"
   },
   "source": [
    "### Mnist classification in a nutshell\n",
    "\n",
    "In the next cell we train a simple fully connected neutal network to classify digits (0-9) form the mnist dataset. We use 20'000 images as our train dataset and 10'000 images are in our testset. Finally we plot the learning cuves and look at some predictions and the accuracy on the testset, you see that we already have an accuracy of around 96%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 835
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24107,
     "status": "ok",
     "timestamp": 1568125360899,
     "user": {
      "displayName": "Elvis Murina",
      "photoUrl": "",
      "userId": "06600021592491010883"
     },
     "user_tz": -120
    },
    "id": "p1iLtgoqfRRj",
    "outputId": "cb64f231-fccb-433b-a298-6297d055254a"
   },
   "outputs": [],
   "source": [
    "(x_digits_train, y_digits_train), (x_digits_test, y_digits_test) = mnist.load_data()\n",
    "\n",
    "# Make train data smaller\n",
    "np.random.seed(72)\n",
    "train_data_idx=np.random.choice(range(0,len(x_digits_train)),20000,replace=False)\n",
    "x_digits_train=x_digits_train[train_data_idx]\n",
    "y_digits_train=y_digits_train[train_data_idx]\n",
    "\n",
    "# Preprocess data \n",
    "x_digits_train = x_digits_train.astype('float32')\n",
    "x_digits_test = x_digits_test.astype('float32')\n",
    "x_digits_train = x_digits_train/ 255\n",
    "x_digits_test = x_digits_test/ 255\n",
    "y_digits_train = to_categorical(y_digits_train, 10)\n",
    "y_digits_test = to_categorical(y_digits_test, 10)\n",
    "x_digits_train=x_digits_train.reshape((len(x_digits_train),28,28,1))\n",
    "x_digits_test=x_digits_test.reshape((len(x_digits_test),28,28,1))\n",
    "\n",
    "\n",
    "# Define model \n",
    "model_digits = Sequential()\n",
    "model_digits.add(Flatten(input_shape=(28,28,1)))\n",
    "model_digits.add(Dense(500, activation='relu'))\n",
    "model_digits.add(Dense(50, activation='relu'))\n",
    "model_digits.add(Dense(10, activation='softmax'))\n",
    "# Compile model\n",
    "model_digits.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "history=model_digits.fit(x_digits_train, y_digits_train,validation_data=(x_digits_test, y_digits_test),\n",
    "                         batch_size=128, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 27794,
     "status": "ok",
     "timestamp": 1568125271304,
     "user": {
      "displayName": "Elvis Murina",
      "photoUrl": "",
      "userId": "06600021592491010883"
     },
     "user_tz": -120
    },
    "id": "uzPx7Yn1fRRm",
    "outputId": "95c94c41-344a-4825-f684-46d1df5ce455"
   },
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='lower right')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 450,
     "status": "ok",
     "timestamp": 1568125779915,
     "user": {
      "displayName": "Elvis Murina",
      "photoUrl": "",
      "userId": "06600021592491010883"
     },
     "user_tz": -120
    },
    "id": "IE0yXOe9fRRp",
    "outputId": "8142bda6-e9ea-4566-ddbd-2a8251643653"
   },
   "outputs": [],
   "source": [
    "# prediction of an image of the testset\n",
    "i=np.random.choice(range(0,len(x_digits_test)))\n",
    "plt.imshow(x_digits_test[i,:,:,0],cmap=\"gray\")\n",
    "pred=model_digits.predict(x_digits_test[i:i+1])\n",
    "print(\"predicted probabilities\",pred)\n",
    "print(\"max probability\",np.max(pred))\n",
    "print(\"predicted label\",np.argmax(pred))\n",
    "print(\"true label\",np.argmax(y_digits_test[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10611,
     "status": "ok",
     "timestamp": 1568124546223,
     "user": {
      "displayName": "Elvis Murina",
      "photoUrl": "",
      "userId": "06600021592491010883"
     },
     "user_tz": -120
    },
    "id": "QP4TRC7JfRRs",
    "outputId": "94e5cb60-c60c-4595-bb07-b1b631b26a2a"
   },
   "outputs": [],
   "source": [
    "#evaluation on the testset\n",
    "model_digits.evaluate(x_digits_test,y_digits_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "41d5timbhPUp"
   },
   "source": [
    "### Mnist classification in more detail\n",
    "\n",
    "Now let's look at the code above in more detail.\n",
    "First we load the mnist dataset and look at the size of the train and test dataset. We have 60'000 train images and 10'000 test iamges. The images are greyscale images and the size is 28x28 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NYrRnn9rfRRy"
   },
   "outputs": [],
   "source": [
    "#Load pre-shuffled MNIST data into train and test sets\n",
    "(x_digits_train, y_digits_train), (x_digits_test, y_digits_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 334,
     "status": "ok",
     "timestamp": 1568124594512,
     "user": {
      "displayName": "Elvis Murina",
      "photoUrl": "",
      "userId": "06600021592491010883"
     },
     "user_tz": -120
    },
    "id": "BQx3U5P0fRR1",
    "outputId": "05e9f40c-abaa-43dd-ecff-a179774ce2ff"
   },
   "outputs": [],
   "source": [
    "print(x_digits_train.shape)\n",
    "print(x_digits_test.shape)\n",
    "\n",
    "print(y_digits_train.shape)\n",
    "print(y_digits_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ywNWisskfRR4"
   },
   "source": [
    "In the next few cells we make the train dataset smaller by sampling 10'000 random images of the 60'000. We look at the distribution of the labels in both datasets and you can see that both dataset are more or less balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 542,
     "status": "ok",
     "timestamp": 1568124596633,
     "user": {
      "displayName": "Elvis Murina",
      "photoUrl": "",
      "userId": "06600021592491010883"
     },
     "user_tz": -120
    },
    "id": "X3hBMYfAfRR5",
    "outputId": "28c6d902-4c1c-4a6b-89ca-720a2c38a410"
   },
   "outputs": [],
   "source": [
    "np.random.seed(72)\n",
    "train_data_idx=np.random.choice(range(0,len(x_digits_test)),10000,replace=False)\n",
    "x_digits_train=x_digits_train[train_data_idx]\n",
    "y_digits_train=y_digits_train[train_data_idx]\n",
    "print(x_digits_train.shape)\n",
    "print(y_digits_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 481,
     "status": "ok",
     "timestamp": 1568124597823,
     "user": {
      "displayName": "Elvis Murina",
      "photoUrl": "",
      "userId": "06600021592491010883"
     },
     "user_tz": -120
    },
    "id": "hj2vE2A4fRR-",
    "outputId": "33d06c67-9636-49cc-c53e-70c9e5c8d357"
   },
   "outputs": [],
   "source": [
    "np.unique(y_digits_train,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 459,
     "status": "ok",
     "timestamp": 1568124598903,
     "user": {
      "displayName": "Elvis Murina",
      "photoUrl": "",
      "userId": "06600021592491010883"
     },
     "user_tz": -120
    },
    "id": "Gidt1HrtfRSB",
    "outputId": "a8a0f4e9-311c-48c3-969c-61e7d94d2551"
   },
   "outputs": [],
   "source": [
    "np.unique(y_digits_test,return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vKHtX2CwfRSE"
   },
   "source": [
    "Let's look at the pixelvalues of a train image, you can see that the values are between 0 and 255.  We normalize the values to be in the range from 0 to 1, by values with 255. If you look at the labels, you see that the lables are values form 0 to 9, to train a neural network we need to transform it to the so called one hot encoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 977
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 477,
     "status": "ok",
     "timestamp": 1568124600695,
     "user": {
      "displayName": "Elvis Murina",
      "photoUrl": "",
      "userId": "06600021592491010883"
     },
     "user_tz": -120
    },
    "id": "-AmyOGA4fRSF",
    "outputId": "88b78407-2a63-46b9-8b75-73fa81a63fc7"
   },
   "outputs": [],
   "source": [
    "#print the pixel values of the first \"image\"\n",
    "print(x_digits_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 655,
     "status": "ok",
     "timestamp": 1568124602121,
     "user": {
      "displayName": "Elvis Murina",
      "photoUrl": "",
      "userId": "06600021592491010883"
     },
     "user_tz": -120
    },
    "id": "Mg0pSVzGfRSI",
    "outputId": "23f9aae9-e507-42ce-82df-11687a2c88c2"
   },
   "outputs": [],
   "source": [
    "#print the label of the first \"image\"\n",
    "print(y_digits_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OvWRm9GVfRSM"
   },
   "outputs": [],
   "source": [
    "# Preprocess data (normalize to be in the range [0,1])\n",
    "x_digits_train = x_digits_train.astype('float32')\n",
    "x_digits_test = x_digits_test.astype('float32')\n",
    "x_digits_train = x_digits_train/ 255\n",
    "x_digits_test = x_digits_test/ 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M0Tl4Ae0fRSQ"
   },
   "outputs": [],
   "source": [
    "# Preprocess class labels -- one hot encoding\n",
    "y_digits_train = to_categorical(y_digits_train, 10)\n",
    "y_digits_test = to_categorical(y_digits_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 519,
     "status": "ok",
     "timestamp": 1568124605688,
     "user": {
      "displayName": "Elvis Murina",
      "photoUrl": "",
      "userId": "06600021592491010883"
     },
     "user_tz": -120
    },
    "id": "FVXYtTbAfRST",
    "outputId": "77730e9c-63b8-44f2-9337-6ece4e11628c",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print the pixel values of the first \"image\"\n",
    "# now the values are form 0 to 1\n",
    "print(x_digits_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 487,
     "status": "ok",
     "timestamp": 1568124610106,
     "user": {
      "displayName": "Elvis Murina",
      "photoUrl": "",
      "userId": "06600021592491010883"
     },
     "user_tz": -120
    },
    "id": "xQDDMe39fRSW",
    "outputId": "d2e07ccf-9a72-430f-f9ca-4bb8df62560f"
   },
   "outputs": [],
   "source": [
    "#print the label of the first \"image\"\n",
    "#the 2 form above, one hot encoded\n",
    "print(y_digits_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 551,
     "status": "ok",
     "timestamp": 1568124642370,
     "user": {
      "displayName": "Elvis Murina",
      "photoUrl": "",
      "userId": "06600021592491010883"
     },
     "user_tz": -120
    },
    "id": "wCgqB1tffRSY",
    "outputId": "19b403c1-5b51-48c1-b7b1-123cc2c63c93"
   },
   "outputs": [],
   "source": [
    "print(x_digits_train.shape)\n",
    "print(x_digits_test.shape)\n",
    "\n",
    "print(y_digits_train.shape)\n",
    "print(y_digits_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jddm3TBqfRSb"
   },
   "source": [
    "Let's plot a few images to get a feeling for the dataset and see how hard the task is.\n",
    "We plot the first 9 images of the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nYtbsoc_8Ptf"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(0,9):\n",
    "    sample_img = x_digits_train[i];\n",
    "    # plot the image\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(sample_img,cmap=\"gray\")\n",
    "    plt.title (\"Label: %s\"%np.where(y_digits_train[i]));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "82u0L84ifRSm"
   },
   "source": [
    "In the next few cells we reshape the train and test dataset to be a 4 dim array. We have grayscale images and only one channel so we add one channel in the last dim. We define a neural network with keras, it has two fully connected layers with 500 and 50 nodes with the relu activation function. The last layer has 10 nodes and the softmax activation function, so we can interpret the output as probability for the predicted label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h1qiRgF_fRSn"
   },
   "outputs": [],
   "source": [
    "x_digits_train=x_digits_train.reshape((len(x_digits_train),28,28,1))\n",
    "x_digits_test=x_digits_test.reshape((len(x_digits_test),28,28,1))\n",
    "\n",
    "print(x_digits_train.shape)\n",
    "print(x_digits_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WfEANXC68Ptl"
   },
   "outputs": [],
   "source": [
    "# Define model architecture\n",
    "model_digits = Sequential()\n",
    "\n",
    "model_digits.add(Flatten(input_shape=(28,28,1)))\n",
    "\n",
    "model_digits.add(Dense(500, activation='relu'))\n",
    "model_digits.add(Dense(50, activation='relu'))\n",
    "model_digits.add(Dense(10, activation='softmax'))\n",
    " \n",
    "# Compile model\n",
    "model_digits.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vrnomeZDfRS1"
   },
   "outputs": [],
   "source": [
    "model_digits.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KIGHyPg_fRS4"
   },
   "source": [
    "In the next two cells we evaluate the untrained model. As you can see the predictions of the untrained model are completely random, we have an accuracy of around 10%. If you look at single image preditions, you see that the predictions are random and wrong for most of the time. This will change when we train the model with our training dataset. To visualize the trainig process, the computational graph and development of the weights you can use Tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y32_q6R0fRS6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluation of the untrained model\n",
    "model_digits.evaluate(x_digits_test,y_digits_test)\n",
    "# you get the loss \"categorical_crossentropy\" and the accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KRTWoq4YfRS-"
   },
   "outputs": [],
   "source": [
    "# prediction of an image with the untrained model\n",
    "i=np.random.choice(range(0,len(x_digits_test)))\n",
    "plt.imshow(x_digits_test[i,:,:,0],cmap=\"gray\")\n",
    "pred=model_digits.predict(x_digits_test[i:i+1])\n",
    "print(\"predicted probabilities\",pred)\n",
    "print(\"max probability\",np.max(pred))\n",
    "print(\"predicted label\",np.argmax(pred))\n",
    "print(\"true label\",np.argmax(y_digits_test[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V8vmkXJsfRTE"
   },
   "outputs": [],
   "source": [
    "tensorboard = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=\"C:\\\\Users\\\\murl\\\\Desktop\\\\cas_2019\\\\tensorboard\\\\mnist\\\\\", write_graph=True,histogram_freq=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lYctOEmR8Pto"
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "history=model_digits.fit(x_digits_train, y_digits_train,validation_data=(x_digits_test,y_digits_test), batch_size=128, epochs=5, verbose=1, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yw12rzEKfRTM"
   },
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='lower right')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S8lJ2b1bfRTP"
   },
   "outputs": [],
   "source": [
    "# open terminal inside the juypter enviroment\n",
    "# type tensorboard --logdir=C:\\Users\\murl\\Desktop\\cas_2019\\tensorboard\\mnist\n",
    "# and then go to http://localhost:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d2RgJQiNfRTT",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluation of the trained model\n",
    "model_digits.evaluate(x_digits_test,y_digits_test)\n",
    "# you get the loss \"categorical_crossentropy\" and the accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Su8HhmC2fRTY"
   },
   "outputs": [],
   "source": [
    "# prediction of an image with the trained model\n",
    "i=np.random.choice(range(0,len(x_digits_test)))\n",
    "plt.imshow(x_digits_test[i,:,:,0],cmap=\"gray\")\n",
    "pred=model_digits.predict(x_digits_test[i:i+1])\n",
    "print(\"predicted probabilities\",pred)\n",
    "print(\"max probability\",np.max(pred))\n",
    "print(\"predicted label\",np.argmax(pred))\n",
    "print(\"true label\",np.argmax(y_digits_test[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5aDv79VffRTf"
   },
   "source": [
    "In the next cells we calculate the accuracy on the test dataset and look at the confusion matrix. We have an accuracy of around 95% which is already very good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PU4v88uHfRTh"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "preds=model_digits.predict_classes(x_digits_test)\n",
    "confusion_matrix(np.argmax(y_digits_test,axis=1),preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1FSk95njfRTl"
   },
   "outputs": [],
   "source": [
    "print(np.average(np.argmax(y_digits_test,axis=1)==preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W8vgm5XwfRTq"
   },
   "source": [
    "### Mnist classification with pure TensorFlow (optional)\n",
    "In the code below you can see how do define and optimize a fully connected neural network in pure TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IcBKZafnfRTr"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784], name='x_data')\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, 10], name='y_data')\n",
    "\n",
    "# From Input to first hidden layer\n",
    "w_1 = tf.Variable(tf.random_normal([784, 500], stddev=0.1))\n",
    "b_1 = tf.Variable(tf.random_normal([500]))\n",
    "h_1_in = tf.add(tf.matmul(x, w_1), b_1)\n",
    "h_1_out = tf.nn.sigmoid(h_1_in)\n",
    "#h_1_out = tf.nn.relu(h_1_in)\n",
    "\n",
    "# From first hidden layer to second hidden layer\n",
    "w_2 = tf.Variable(tf.random_normal([500, 50], stddev=0.01))\n",
    "b_2 = tf.Variable(tf.random_normal([50]))\n",
    "h_2_in = tf.add(tf.matmul(h_1_out, w_2), b_2)\n",
    "h_2_out = tf.nn.sigmoid(h_2_in)\n",
    "#h_2_out = tf.nn.relu(h_2_in)\n",
    "\n",
    "# From second hidden layer to output\n",
    "w_3 = tf.Variable(tf.random_normal([50, 10], stddev=0.01))\n",
    "b_3 = tf.Variable(tf.random_normal([10]))\n",
    "h_3_in = tf.add(tf.matmul(h_2_out, w_3), b_3)\n",
    "\n",
    "# Output is softmax\n",
    "out = tf.nn.softmax(h_3_in)\n",
    "init_op = tf.global_variables_initializer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fb7TDcsLfRTt"
   },
   "outputs": [],
   "source": [
    "tf.summary.FileWriter(\"C:\\\\Users\\\\murl\\\\Desktop\\\\cas_2019\\\\tensorboard\\\\tf_mnist\\\\\", tf.get_default_graph()) #<--- Where to store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZZldwRIUfRTw"
   },
   "outputs": [],
   "source": [
    "x_digits_train_flat=x_digits_train.reshape((len(x_digits_train),28*28*1))\n",
    "x_digits_test_flat=x_digits_test.reshape((len(x_digits_test),28*28*1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DA9XnhutfRTy"
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    res_val = sess.run(out, feed_dict={x:x_digits_train_flat[0:1]})\n",
    "res_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-nkGqpyefRT0"
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(-tf.reduce_sum(y_true * tf.log(out), reduction_indices=[1]))\n",
    "train_op = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n",
    "init_op = tf.global_variables_initializer() \n",
    "vals = []\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    for i in range(4000):\n",
    "        idx = np.random.permutation(2400)[0:128] #simple minibatch of size 128\n",
    "        loss_, _, res_ = sess.run((loss, train_op,out), feed_dict={x:x_digits_train_flat[idx], y_true:y_digits_train[idx]})\n",
    "        if (i % 100 == 0):\n",
    "            # Get the results for the whole train data\n",
    "            acc = np.average(np.argmax(res_, axis = 1) == np.argmax(y_digits_train,axis=1)[idx])\n",
    "            loss_v, res_val = sess.run([loss, out], feed_dict={x:x_digits_train_flat, y_true:y_digits_train})\n",
    "            acc_v = np.average(np.argmax(res_val, axis = 1) == np.argmax(y_digits_train,axis=1))\n",
    "            vals.append([loss_, acc, loss_v, acc_v])\n",
    "            print(\"{} Training: batch_loss {} batch_acc {}  total_train_loss {} total_train_acc {}\".format(i, loss_, acc, loss_v, acc_v))\n",
    "    #Get test performance after the 4000 updates        \n",
    "    loss_test, pred_test = sess.run([loss, out], feed_dict={x:x_digits_test_flat, y_true:y_digits_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r0dgJDt6fRT3"
   },
   "outputs": [],
   "source": [
    "confusion_matrix(np.argmax(y_digits_test,axis=1),np.argmax(pred_test,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o6xeUZaQfRT5"
   },
   "outputs": [],
   "source": [
    "print(np.average(np.argmax(y_digits_test,axis=1)==np.argmax(pred_test,axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vPN6Fo1wfRT7"
   },
   "source": [
    "### Exercise \n",
    "\n",
    "Train the same neural network with fewer and more training data. train with 100,1000 and the full training data. Look at the learning curves of each model and evaluate the performace on the test dataset, what do you observe? Play around with the nr of the hidden layer and with the nr of nodes. What do you observe?  \n",
    "*Hint: You might need to train for more than just 5 epochs*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AcNR1tXCfRT8"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "01_notebook.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
