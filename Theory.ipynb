{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v40z8HXr9qzX"
   },
   "source": [
    "# Optimization\n",
    "\n",
    "## 1d example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-qVTmSOb9qzi"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def show_trace(res):\n",
    "    n = max(abs(min(res)), abs(max(res)))\n",
    "    f_line = np.arange(-n, n, 0.01)\n",
    "    plt.plot(f_line, [f(x) for x in f_line], label=\"x\")\n",
    "    plt.plot(res, [f(x) for x in res], '-o', label=\"f(x)\")\n",
    "    plt.legend()\n",
    "             \n",
    "\n",
    "def f(x):     return x**2  # objective function\n",
    "def gradf(x): return 2 * x # its derivative\n",
    "\n",
    "#c = 0.15 * math.pi\n",
    "#def f(x):     return x*math.cos(c * x)\n",
    "#def gradf(x): return math.cos(c * x) - c * x * math.sin(c * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SdOiJ2MO9qz6",
    "outputId": "ea4e36e1-c085-41f6-a9ee-f60dae3b5e8e"
   },
   "outputs": [],
   "source": [
    "#simple random search\n",
    "\n",
    "def rand(x0, x_low, x_high, steps):    \n",
    "    x = x0\n",
    "    best = f(x0)\n",
    "    results = [x]\n",
    "    results_error = [best]\n",
    "    for i in range(steps):\n",
    "        x_n = np.random.uniform(x_low, x_high)                \n",
    "        if f(x_n) < best:\n",
    "            x = x_n\n",
    "            best = f(x_n)\n",
    "        results.append(x)\n",
    "        results_error.append(best)\n",
    "    print ('x:    ' ,x)\n",
    "    print ('f(x): ', f(x))    \n",
    "    return results, results_error\n",
    "    \n",
    "steps = 100\n",
    "res_rand = rand(10, -1000, 1000, steps)\n",
    "#show_trace(res_rand[0])\n",
    "\n",
    "plt.figure(figsize=[12, 4]);\n",
    "plt.subplot(1,2,1)\n",
    "show_trace(res_rand[0])\n",
    "plt.grid()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot (range(steps+1), res_rand[1])\n",
    "plt.grid()\n",
    "plt.xlabel(\"iterations\"), plt.ylabel (\"loss\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LbTI5w_-9q0X",
    "outputId": "79e341fe-b1c7-4f4b-e4a9-8b2f9f827b96"
   },
   "outputs": [],
   "source": [
    "#random search (incrementell)\n",
    "def rand2(x0, r, steps):    \n",
    "    x = x0\n",
    "    best = f(x0)\n",
    "    results = [x]\n",
    "    results_error = [best]\n",
    "    for i in range(steps):\n",
    "        x_n = x + np.random.uniform(-r, r)        \n",
    "        if f(x_n) < best:\n",
    "            x = x_n\n",
    "            best = f(x_n)\n",
    "        results.append(x)\n",
    "        results_error.append(best)\n",
    "    print ('x:    ' ,x)\n",
    "    print ('f(x): ', f(x))    \n",
    "    return results, results_error\n",
    "\n",
    "res_rand2 = rand2(10, 2, steps)\n",
    "\n",
    "plt.figure(figsize=[12, 4]);\n",
    "plt.subplot(1,2,1)\n",
    "show_trace(res_rand2[0])\n",
    "plt.grid()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot (range(steps+1), res_rand[1], label=\"rand\")\n",
    "plt.plot (range(steps+1), res_rand2[1], label=\"randI\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel(\"iterations\"), plt.ylabel (\"loss\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sGDs9OTC9q0s",
    "outputId": "8709fa7a-40b7-422c-930d-2ba848575630"
   },
   "outputs": [],
   "source": [
    "#gradient descent\n",
    "\n",
    "def gd(x0, eta, steps):\n",
    "    x = x0\n",
    "    results = [x]\n",
    "    results_error = [f(x)]\n",
    "    for i in range(steps):\n",
    "        x = x - eta * gradf(x)\n",
    "        results.append(x)\n",
    "        results_error.append(f(x))\n",
    "    print('x:    ', x)\n",
    "    print('f(x): ', f(x))\n",
    "    return results, results_error\n",
    "\n",
    "res_gd = gd(10, 1, steps)\n",
    "\n",
    "plt.figure(figsize=[12, 4]);\n",
    "plt.subplot(1,2,1)\n",
    "show_trace(res_gd[0])\n",
    "plt.grid()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot (range(steps+1), res_rand[1], label=\"rand\")\n",
    "plt.plot (range(steps+1), res_rand2[1], label=\"randI\")\n",
    "plt.plot (range(steps+1), res_gd[1], label=\"gd\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel(\"iterations\"), plt.ylabel (\"loss\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2d example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def show_trace2d(res):\n",
    "    n = 10\n",
    "    x_line = np.arange(-n, n, 0.1)\n",
    "    y_line = np.arange(-n, n, 0.1)\n",
    "    X, Y = np.meshgrid(x_line, y_line)\n",
    "    F = f(X,Y)\n",
    "    cp = plt.contour(X,Y,F)\n",
    "    plt.clabel(cp, inline=True, fontsize=10)\n",
    "    plt.plot([i[0] for i in res], [i[1] for i in res], '-o')\n",
    "\n",
    "def f(x,y):     return x**2 + 2*y**2\n",
    "def gradf_x(x,y): return 2*x\n",
    "def gradf_y(x,y): return 4*y\n",
    "\n",
    "def rand_2d(x0, y0, x_low, x_high, y_low, y_high, steps):    \n",
    "    x = x0\n",
    "    y = y0\n",
    "    best = f(x0,y0)\n",
    "    results = [(x,y)]\n",
    "    results_error = [best]\n",
    "    for i in range(steps):\n",
    "        x_n = np.random.uniform(x_low, x_high)\n",
    "        y_n = np.random.uniform(y_low, y_high)\n",
    "        if f(x_n,y_n) < best:\n",
    "            x = x_n\n",
    "            y = y_n\n",
    "            best = f(x_n,y_n)\n",
    "        results.append((x,y))\n",
    "        results_error.append(best)\n",
    "    print ('x:      ' ,x)\n",
    "    print ('y:      ', y)\n",
    "    print ('f(x,y): ', f(x,y))    \n",
    "    return results, results_error\n",
    "\n",
    "def rand2(x0, y0, r, steps):    \n",
    "    x = x0\n",
    "    y = y0\n",
    "    best = f(x0,y0)\n",
    "    results = [(x,y)]\n",
    "    results_error = [best]\n",
    "    for i in range(steps):\n",
    "        x_n = x + np.random.uniform(-r, r)\n",
    "        y_n = y + np.random.uniform(-r, r)\n",
    "        if f(x_n,y_n) < best:\n",
    "            x = x_n\n",
    "            y = y_n\n",
    "            best = f(x_n, y_n)\n",
    "        results.append((x,y))\n",
    "        results_error.append(best)\n",
    "    print ('x:      ' ,x)\n",
    "    print ('y:      ', y)\n",
    "    print ('f(x,y): ', f(x,y))    \n",
    "    return results, results_error\n",
    "\n",
    "def gd_2d(x0, y0, eta, steps):\n",
    "    x = x0\n",
    "    y = y0\n",
    "    results = [(x,y)]\n",
    "    results_error = [f(x,y)]\n",
    "    for i in range(steps):\n",
    "        x -= eta * gradf_x(x,y)\n",
    "        y -= eta * gradf_y(x,y)\n",
    "        results.append((x,y))\n",
    "        results_error.append(f(x,y))\n",
    "    print('x:      ', x)\n",
    "    print('y:      ', y)\n",
    "    print('f(x,y): ', f(x,y))\n",
    "    return results, results_error\n",
    "\n",
    "\n",
    "steps= 100                       \n",
    "res_rand = rand_2d(10,10, -100, 100, -100, 10, steps)                       \n",
    "\n",
    "plt.figure(figsize=[12, 4]);\n",
    "plt.subplot(1,2,1)\n",
    "show_trace2d(res_rand[0])\n",
    "plt.grid()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot (range(steps+1), res_rand[1], label=\"rand\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel(\"iterations\"), plt.ylabel (\"loss\");                       \n",
    "                       \n",
    "res_rand2 = rand2(10, 10, 2, steps)\n",
    "\n",
    "plt.figure(figsize=[12, 4]);\n",
    "plt.subplot(1,2,1)\n",
    "show_trace2d(res_rand2[0])\n",
    "plt.grid()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot (range(steps+1), res_rand[1], label=\"rand\")\n",
    "plt.plot (range(steps+1), res_rand2[1], label='randI')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel(\"iterations\"), plt.ylabel (\"loss\");\n",
    "\n",
    "res_gd = gd_2d(10, 10, 0.2, steps)\n",
    "\n",
    "plt.figure(figsize=[12, 4]);\n",
    "plt.subplot(1,2,1)\n",
    "show_trace2d(res_gd[0])\n",
    "plt.grid()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot (range(steps+1), res_rand[1], label=\"rand\")\n",
    "plt.plot (range(steps+1), res_rand2[1], label='randI')\n",
    "plt.plot (range(steps+1), res_gd[1], label='gd')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel(\"iterations\"), plt.ylabel (\"loss\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yk-LGNwo9q08"
   },
   "source": [
    "# Deep Learning Discussions\n",
    "\n",
    "## MNIST Hello World (as before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotTraining(history):\n",
    "    # summarize history for accuracy\n",
    "    plt.figure(figsize=(14,6))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'valid'], loc='lower right')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'valid'], loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bea1u4m49q1D",
    "outputId": "4dd1fc51-88b7-452f-8488-c64d73aa51f0"
   },
   "outputs": [],
   "source": [
    "# hello world example\n",
    "\n",
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=5)\n",
    "plotTraining(history)\n",
    "\n",
    "model.evaluate(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "522UyJtaLQ5J"
   },
   "source": [
    "## Activation Functions\n",
    "\n",
    "- Differnt Types of Activation Functions. What do you obeserve? Training speed, final performance, etc...\n",
    "- Why do we need them at all?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "whllDBRS9q1V",
    "outputId": "93772e01-ba8b-4964-f0da-0e7a53451896"
   },
   "outputs": [],
   "source": [
    "# no activation function (linear)\n",
    "# https://keras.io/activations/\n",
    "\n",
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  \n",
    "  #PLAY AROUND HERE\n",
    "  \n",
    "  tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "  #tf.keras.layers.Dense(64), #linear\n",
    "  #tf.keras.layers.Dense(64, activation=tf.nn.sigmoid),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=3)\n",
    "plotTraining(history)\n",
    "\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "niSWIKTBLQ5M"
   },
   "source": [
    "## Optimization - Weight initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sUFJvBTz9q1k",
    "outputId": "91e4fe93-e184-47c0-aa7d-f938737655f0"
   },
   "outputs": [],
   "source": [
    "# weight initialization\n",
    "# https://keras.io/initializers/\n",
    "\n",
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  \n",
    "  #PLAY AROUND HERE\n",
    "  \n",
    "  #tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "  #tf.keras.layers.Dense(64, activation=tf.nn.relu,  kernel_initializer=tf.keras.initializers.Zeros()),\n",
    "  #tf.keras.layers.Dense(64, activation=tf.nn.relu,  kernel_initializer=tf.keras.initializers.Constant(value=-1)),\n",
    "  tf.keras.layers.Dense(64, activation=tf.nn.relu,  kernel_initializer=tf.keras.initializers.Constant(value=1)),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=3)\n",
    "plotTraining(history)\n",
    "\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sFju7L0fLQ5P"
   },
   "source": [
    "## Optimization - Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7GKQ32LB9q13",
    "outputId": "6a89268a-f284-4f16-9b83-ada492951d2f"
   },
   "outputs": [],
   "source": [
    "# optimizer & stochastic gradient descent\n",
    "# https://keras.io/optimizers/\n",
    "\n",
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "#PLAY AROUND HERE\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "#model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10)\n",
    "#history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=3, batch_size=1) #sgd\n",
    "#history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=3, batch_size=len(x_train)) #batch gradient descent\n",
    "#history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=3, batch_size=64) #32 default\n",
    "plotTraining(history)\n",
    "\n",
    "model.evaluate(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oHlaudXKw7dj"
   },
   "source": [
    "## Data Augmentation to increase performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no data augmentation\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Make train data smaller -- only 100 examples!\n",
    "np.random.seed(36)\n",
    "train_data_idx=np.random.choice(range(0,len(x_train)),100,replace=False)\n",
    "x_train=x_train[train_data_idx]\n",
    "y_train=y_train[train_data_idx]\n",
    "\n",
    "x_train=x_train.reshape((len(x_train),28,28,1))\n",
    "x_test=x_test.reshape((len(x_test),28,28,1))\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28,1)),\n",
    "  tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=25, validation_data=(x_test, y_test))\n",
    "plotTraining(history)\n",
    "\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V19CHcvHjbzc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# do data aug\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15)\n",
    "\n",
    "i=2\n",
    "data_aug=datagen.flow(x=x_train[i:(i+1)], y=y_train[i:(i+1)], batch_size=1)\n",
    "plt.imshow(x_train[i,:,:,0],cmap=\"gray\")\n",
    "# original image`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3298,
     "status": "ok",
     "timestamp": 1568130516880,
     "user": {
      "displayName": "Elvis Murina",
      "photoUrl": "",
      "userId": "06600021592491010883"
     },
     "user_tz": -120
    },
    "id": "-6pLHKMej3rs",
    "outputId": "b1b7c9aa-d8f7-44c9-c497-37ae953eb7d3"
   },
   "outputs": [],
   "source": [
    "# augmented image\n",
    "plt.figure(figsize=(15,15))\n",
    "for i in range (0,25):\n",
    "  plt.subplot(5,5,i+1)\n",
    "  x_aug,y_aug=next(data_aug)\n",
    "  plt.imshow(x_aug[0,:,:,0],cmap=\"gray\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Make train data smaller -- only 100 examples!\n",
    "np.random.seed(36)\n",
    "train_data_idx=np.random.choice(range(0,len(x_train)),100,replace=False)\n",
    "x_train=x_train[train_data_idx]\n",
    "y_train=y_train[train_data_idx]\n",
    "\n",
    "x_train=x_train.reshape((len(x_train),28,28,1))\n",
    "x_test=x_test.reshape((len(x_test),28,28,1))\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15)\n",
    "\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=32), steps_per_epoch=len(x_train), epochs=20, validation_data=(x_test, y_test))\n",
    "plotTraining(history)\n",
    "\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KDaS5HnAxZpw"
   },
   "source": [
    "### Accuracy on the test set is aroud 10% better if you use data augmentation\n",
    "\n",
    "0.7491 -> 0.8349"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Architecture: CNN\n",
    "\n",
    "model from scratch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model, clone_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(x_digits_train, y_digits_train), (x_digits_test, y_digits_test) = mnist.load_data()\n",
    "\n",
    "# Make train data smaller\n",
    "np.random.seed(36)\n",
    "train_data_idx=np.random.choice(range(0,len(x_digits_train)),100,replace=False)\n",
    "x_digits_train=x_digits_train[train_data_idx]\n",
    "y_digits_train=y_digits_train[train_data_idx]\n",
    "\n",
    "# Preprocess data \n",
    "x_digits_train = x_digits_train.astype('float32')\n",
    "x_digits_test = x_digits_test.astype('float32')\n",
    "x_digits_train = x_digits_train/ 255\n",
    "x_digits_test = x_digits_test/ 255\n",
    "x_digits_train=x_digits_train.reshape((len(x_digits_train),28,28,1))\n",
    "x_digits_test=x_digits_test.reshape((len(x_digits_test),28,28,1))\n",
    "\n",
    "\n",
    "# Define model \n",
    "model_digits = Sequential()\n",
    "model_digits.add(Conv2D(8,(3,3),activation='relu',input_shape=(28,28,1)))\n",
    "model_digits.add(Conv2D(8,(3,3),activation='relu'))\n",
    "model_digits.add(MaxPooling2D((2,2)))\n",
    "model_digits.add(Conv2D(16,(3,3),activation='relu'))\n",
    "model_digits.add(Conv2D(16,(3,3),activation='relu'))\n",
    "model_digits.add(Flatten())\n",
    "model_digits.add(Dense(50, activation='relu'))\n",
    "model_digits.add(Dense(10, activation='softmax'))\n",
    "# Compile model\n",
    "model_digits.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "history=model_digits.fit(x_digits_train, y_digits_train,validation_data=(x_digits_test, y_digits_test),\n",
    "                         batch_size=128, epochs=80)\n",
    "plotTraining(history)\n",
    "\n",
    "model_digits.evaluate(x_digits_test,y_digits_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN + Data-Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15)\n",
    "\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "history=model_digits.fit_generator(datagen.flow(x_digits_train, y_digits_train, batch_size=64),validation_data=(x_digits_test, y_digits_test),\n",
    "                    steps_per_epoch=len(x_digits_train) / 64, epochs=120)\n",
    "plotTraining(history)\n",
    "\n",
    "model_digits.evaluate(x_digits_test,y_digits_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test performance summary (so far)\n",
    "\n",
    "- simple model:\n",
    " \n",
    "         0.7491 -> 0.8349\n",
    "    \n",
    "    \n",
    "- CNN (for other task, much much higher!):\n",
    "    \n",
    "        0.7685 -> 0.8414"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN + Fine-Tuning\n",
    "\n",
    "- train a model on letters (E-MNIST)\n",
    "- fix lower layers and fine-tune to digits (MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 56931,
     "status": "ok",
     "timestamp": 1568130681867,
     "user": {
      "displayName": "Elvis Murina",
      "photoUrl": "",
      "userId": "06600021592491010883"
     },
     "user_tz": -120
    },
    "id": "sJJy2JP9hwXe",
    "outputId": "42c20477-22f8-431f-a708-5626604bc8c5"
   },
   "outputs": [],
   "source": [
    "# Downloading the data, if it does not exist (takes some time)\n",
    "import urllib\n",
    "import os\n",
    "if not os.path.isfile('emnist-letters.mat'):\n",
    "    urllib.request.urlretrieve(\n",
    "    \"https://www.dropbox.com/s/pdrbel0f83jxp2n/emnist-letters.mat?dl=1\",  \n",
    "    \"emnist-letters.mat\")\n",
    "%ls -hl emnist-letters.mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mmx7Cf8mgHJY"
   },
   "outputs": [],
   "source": [
    "#load emnist data\n",
    "from scipy import io as spio\n",
    "\n",
    "emnist = spio.loadmat(\"emnist-letters.mat\")\n",
    "\n",
    "# load training dataset\n",
    "x_letter_train = emnist[\"dataset\"][0][0][0][0][0][0]\n",
    "y_letter_train = emnist[\"dataset\"][0][0][0][0][0][1]\n",
    "\n",
    "# load test dataset\n",
    "x_letter_test = emnist[\"dataset\"][0][0][1][0][0][0]\n",
    "y_letter_test = emnist[\"dataset\"][0][0][1][0][0][1]\n",
    "\n",
    "x_letter_train = x_letter_train.reshape(x_letter_train.shape[0], 28, 28, 1, order=\"A\")\n",
    "x_letter_test = x_letter_test.reshape(x_letter_test.shape[0], 28, 28, 1, order=\"A\")\n",
    "x_letter_train = x_letter_train.astype('float32')\n",
    "x_letter_test = x_letter_test.astype('float32')\n",
    "x_letter_train /= 255\n",
    "x_letter_test /= 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4191,
     "status": "ok",
     "timestamp": 1568130691864,
     "user": {
      "displayName": "Elvis Murina",
      "photoUrl": "",
      "userId": "06600021592491010883"
     },
     "user_tz": -120
    },
    "id": "t1C8C78Pgdk_",
    "outputId": "cc02431f-2cec-40d3-dbb3-3ee7f04d4825"
   },
   "outputs": [],
   "source": [
    "# first 25 letters\n",
    "plt.figure(figsize=(15,15))\n",
    "for i in range (0,25):\n",
    "  plt.subplot(5,5,i+1)\n",
    "  plt.imshow(x_letter_train[i,:,:,0],cmap=\"gray\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 635
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 38762,
     "status": "ok",
     "timestamp": 1568131187106,
     "user": {
      "displayName": "Elvis Murina",
      "photoUrl": "",
      "userId": "06600021592491010883"
     },
     "user_tz": -120
    },
    "id": "XuJ3w3oAsYha",
    "outputId": "dc797b51-a7dd-4578-9ce9-f91a4692416d"
   },
   "outputs": [],
   "source": [
    "# Define model \n",
    "model_letters = Sequential()\n",
    "model_letters.add(Conv2D(8,(3,3), activation='relu',input_shape=(28,28,1)))\n",
    "model_letters.add(Conv2D(8,(3,3), activation='relu'))\n",
    "model_letters.add(MaxPooling2D((2,2)))\n",
    "model_letters.add(Conv2D(16,(3,3), activation='relu'))\n",
    "model_letters.add(Conv2D(16,(3,3), activation='relu'))\n",
    "model_letters.add(MaxPooling2D((2,2)))\n",
    "model_letters.add(Flatten(name=\"Flat\"))\n",
    "model_letters.add(Dense(50, activation='relu'))\n",
    "model_letters.add(Dense(27, activation='softmax'))\n",
    "# Compile model\n",
    "model_letters.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "history=model_letters.fit(x_letter_train, y_letter_train,validation_data=(x_letter_test, y_letter_test),\n",
    "                         batch_size=128, epochs=5, verbose=1)\n",
    "plotTraining(history)\n",
    "\n",
    "model_letters.evaluate(x_letter_test,y_letter_test)\n",
    "model_letters.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2lNTdUNfjfhC"
   },
   "outputs": [],
   "source": [
    "letter_model = Model(inputs=model_letters.input, outputs=model_letters.get_layer(\"Flat\").output)\n",
    "letter_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i9cqs9a0h1lV"
   },
   "outputs": [],
   "source": [
    "x = letter_model.output\n",
    "# add a hidden and the new output layer\n",
    "x = Dense(50, activation='relu')(x)\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=letter_model.input, outputs=predictions)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "irtGhsEKkmwp"
   },
   "outputs": [],
   "source": [
    "#fix the lower layers\n",
    "for layer in letter_model.layers:\n",
    "    layer.trainable = False\n",
    "for i, layer in enumerate(model.layers):\n",
    "   print(i, layer.name,layer.trainable)\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 31367,
     "status": "ok",
     "timestamp": 1568131625999,
     "user": {
      "displayName": "Elvis Murina",
      "photoUrl": "",
      "userId": "06600021592491010883"
     },
     "user_tz": -120
    },
    "id": "xXu0onTTuCPE",
    "outputId": "825ae397-22f3-41e1-8147-46635c4f8696",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train\n",
    "history=model.fit(x_digits_train, y_digits_train,validation_data=(x_digits_test, y_digits_test),\n",
    "                         batch_size=64, epochs=80)\n",
    "plotTraining(history)\n",
    "\n",
    "model.evaluate(x_digits_test,y_digits_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c_TenR38yFB1"
   },
   "source": [
    "### Test performance summary (so far)\n",
    "\n",
    "- simple model:\n",
    " \n",
    "         0.7491 -> 0.8349 (data ug.)\n",
    "    \n",
    "    \n",
    "- CNN (for other task, much much higher!):\n",
    "    \n",
    "        0.7685 -> 0.8414 (data aug.)\n",
    "        0.7685 -> 0.8974 (fine-tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yjYlDyxf4K_6"
   },
   "source": [
    "##  CNN + Data augmentation and Fine-Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 692
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28961,
     "status": "ok",
     "timestamp": 1568131626000,
     "user": {
      "displayName": "Elvis Murina",
      "photoUrl": "",
      "userId": "06600021592491010883"
     },
     "user_tz": -120
    },
    "id": "d4pIq-iG4VYs",
    "outputId": "f500abd6-8f03-40b9-f3c9-7587c37eb9c4"
   },
   "outputs": [],
   "source": [
    "letter_model = Model(inputs=model_letters.input, outputs=model_letters.get_layer(\"Flat\").output)\n",
    "\n",
    "x = letter_model.output\n",
    "x = Dense(50, activation='relu')(x)\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "model = Model(inputs=letter_model.input, outputs=predictions)\n",
    "for layer in letter_model.layers:\n",
    "    layer.trainable = False   \n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15)\n",
    "\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "history=model.fit_generator(datagen.flow(x_digits_train, y_digits_train, batch_size=64),validation_data=(x_digits_test, y_digits_test),\n",
    "                    steps_per_epoch=len(x_digits_train) / 64, epochs=120)\n",
    "plotTraining(history)\n",
    "\n",
    "model.evaluate(x_digits_test,y_digits_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jAkoO7i665kJ"
   },
   "source": [
    "### Test performance summary\n",
    "**trained ussing 100 images only!**\n",
    "\n",
    "- simple model:\n",
    " \n",
    "         0.7491 -> 0.8349 (data ug.)\n",
    "    \n",
    "- CNN (for other task, much much higher!):\n",
    "    \n",
    "        0.7685 -> 0.8414 (data aug.)\n",
    "        0.7685 -> 0.8974 (fine-tuning)\n",
    "        0.7685 -> 0.9251 (data aug. & fine-tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wbSZAHpjzhWR"
   },
   "source": [
    "## Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 635
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 37241,
     "status": "ok",
     "timestamp": 1568114241158,
     "user": {
      "displayName": "Elvis Murina",
      "photoUrl": "",
      "userId": "06600021592491010883"
     },
     "user_tz": -120
    },
    "id": "ObUe8FSv0XFb",
    "outputId": "eac300ff-cc33-41d8-c0b4-cd71ee9cee57"
   },
   "outputs": [],
   "source": [
    "## same network from scratch using all training data\n",
    "\n",
    "(x_digits_train, y_digits_train), (x_digits_test, y_digits_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "# Preprocess data \n",
    "x_digits_train = x_digits_train.astype('float32')\n",
    "x_digits_test = x_digits_test.astype('float32')\n",
    "x_digits_train = x_digits_train/ 255\n",
    "x_digits_test = x_digits_test/ 255\n",
    "x_digits_train=x_digits_train.reshape((len(x_digits_train),28,28,1))\n",
    "x_digits_test=x_digits_test.reshape((len(x_digits_test),28,28,1))\n",
    "\n",
    "\n",
    "# Define model \n",
    "model_digits_full = Sequential()\n",
    "model_digits_full.add(Conv2D(16,(3,3),activation='relu',input_shape=(28,28,1)))\n",
    "model_digits_full.add(Conv2D(16,(3,3),activation='relu'))\n",
    "model_digits_full.add(MaxPooling2D((2,2)))\n",
    "model_digits_full.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model_digits_full.add(Conv2D(32,(3,3),activation='relu'))\n",
    "\n",
    "model_digits_full.add(Flatten())\n",
    "model_digits_full.add(Dense(50, activation='relu'))\n",
    "model_digits_full.add(Dense(10, activation='softmax'))\n",
    "# Compile model\n",
    "model_digits_full.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "history=model_digits_full.fit(x_digits_train, y_digits_train,validation_data=(x_digits_test, y_digits_test),\n",
    "                         batch_size=128, epochs=5, verbose=1)\n",
    "plotTraining(history)\n",
    "\n",
    "model_digits_full.evaluate(x_digits_test,y_digits_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2218,
     "status": "ok",
     "timestamp": 1568114244088,
     "user": {
      "displayName": "Elvis Murina",
      "photoUrl": "",
      "userId": "06600021592491010883"
     },
     "user_tz": -120
    },
    "id": "Nukmu912wOg1",
    "outputId": "903d4a5c-7e1a-42f2-9ff6-6438802a0cd0"
   },
   "outputs": [],
   "source": [
    "wrong_idx=np.where(np.argmax(model_digits_full.predict(x_digits_test), axis=1)!=(y_digits_test))[0]\n",
    "len(wrong_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6225,
     "status": "ok",
     "timestamp": 1568114250726,
     "user": {
      "displayName": "Elvis Murina",
      "photoUrl": "",
      "userId": "06600021592491010883"
     },
     "user_tz": -120
    },
    "id": "oiVD575vzt5V",
    "outputId": "d04434b9-4d26-4aa0-930c-00c62f9490f7"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,40))\n",
    "for i in range(0,50):\n",
    "  plt.subplot(10,5,i+1)\n",
    "  plt.imshow(x_digits_test[wrong_idx[i],:,:,0],cmap=\"gray\")\n",
    "  plt.title(\"pred: \"+np.str(np.argmax(model_digits_full.predict(x_digits_test[wrong_idx[i:(i+1)]]), axis=1)[0])+ \" true: \"+np.str((y_digits_test[wrong_idx[i]])))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Theory.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
